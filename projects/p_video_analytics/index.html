<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Live Video Analytics | Francesco Bronzino</title> <meta name="author" content="Francesco Bronzino"> <meta name="description" content=""> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://fbronzino.com/projects/p_video_analytics/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Francesco Bronzino</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research</a> </li> <li class="nav-item "> <a class="nav-link" href="/group/">Group</a> </li> <li class="nav-item "> <a class="nav-link" href="/positions/">Positions</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Live Video Analytics</h1> <p class="post-description"></p> </header> <article> <p>We tackle the challenge of executing diverse machine learning pipelines on heterogeneous computing resources at the network edge. A compelling example of this challenge is live video analytics, which has emerged as a key network application of the future, driven by advances in neural network-based video processing and the rise of edge computing. Existing solutions, however, predominantly target fixed cameras, whose video streams follow a predictable path through a hierarchical network of clusters to execute vision pipelines. With the growing accessibility and widespread adoption of mobile cameras and devices, it is increasingly essential to incorporate these dynamic video feeds into analytics architectures. Our work focuses on integrating mobile devices into analytics platforms by developing innovative system solutions that address the unique and dynamic nature of these devices.</p> <h2 id="videojam-self-balancing-architecture-for-live-video-analytics">VideoJam: Self-Balancing Architecture for Live Video Analytics</h2> <p><em>Abstract.</em> Edge-based live video analytics are a promising approach to reduce bandwidth overheads caused by the transmission of raw video streams to the cloud. However, the limited resources available on edge devices make it challenging to successfully process video streams in real-time. This gets further exacerbated when attempting to process video streams from mobile cameras. While mobile cameras are a desirable source of information, thanks to them being in the right place at the right time, they are inherently dynamic and unpredictable. To address these challenges, we propose VideoJam, a decentralized load balancing solution for live video analytics. VideoJam uses a set of load balancers to balance incoming video traffic across replicas without the need of centralized coordination. Exploiting the inherent load dynamicity generated by different video sources, VideoJam predicts the incoming load for each processing component and offloads excessive traffic to less- loaded neighbors. Further, VideoJam operates independently of deployed configurations and cameras present in the system, dynamically adapting to handle load changes and balance video traffic across available resources. Our evaluation shows that VideoJam can adapt to different mixes of mobile and fixed cameras, as well as quickly adapting to configuration changes occurring at runtime. Compared to state-of-the-art solutions, VideoJam achieves 2.91x lower response time, while reducing video data loss by more than 4.64x and generating lower bandwidth overheads.</p> <h3 id="resources">Resources</h3> <p>The research paper was accepted to ACM/IEEE SEC 2024.</p> <p>Source code: <a href="https://github.com/ENSL-NS/VideoJam" rel="external nofollow noopener" target="_blank">https://github.com/ENSL-NS/VideoJam</a></p> <h3 id="citation-bibtex">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{faye2024videojam,
  title={VideoJam: Self-Balancing Architecture for Live Video Analytics},
  author={Faye, Youssouph and Faticanti, Francescomaria and Jain, Shubham and Bronzino, Francesco},
  journal={IEEE/ACM Symposium on Edge Computing},
  year={2024}
}
</code></pre></div></div> <h2 id="ovida-orchestrator-for-video-analytics-on-disaggregated-architecture">OVIDA: Orchestrator for Video Analytics on Disaggregated Architecture</h2> <p><em>Abstract.</em> Millions of video cameras are deployed globally across major cities for learning-based video analytic (VA) applications, such as object detection. Video streams from the cameras are either sent over the wide-area network to be processed by the cloud or are (at least partially) processed in a local edge workstation, incurring significant latency and elevated financial costs. In this paper, to minimize reliance on the cloud and overcome the unavailability of high-compute workstations on edge, we investigate the use of heterogeneous and distributed embedded devices as edge nodes shared by multiple cameras to fully serve the video processing needs of a VA application (without requiring cloud support). We present OVIDA, an edge-only orchestrator to deploy VA application(s) on a distributed edge environment to maximize accuracy. Given the resource-constrained nature of edge nodes, OVIDA disaggregates the VA application pipeline into multiple modules. OVIDA’s core functionality and contributions are: (i) optimizing the placement and replication of the VA application modules across the edge nodes to maximize the throughput, and in turn, accuracy; and (ii) an adaptive model selection algorithm for VA modules based on accuracy-throughput trade-off to maximize accuracy in response to varying load conditions. To further improve performance, OVIDA employs a central-queue– based design (instead of the usual push-based design), which also obviates the need for complex load balancing algorithms. We implement OVIDA on top of Kubernetes and evaluate its performance for three VA applications, supported over a heterogeneous edge cluster under varying network conditions. When compared against several baselines in our evaluation, we achieve throughput and accuracy gains of at least 51% and 28%.</p> <h3 id="resources-1">Resources</h3> <p>The research paper was accepted to ACM/IEEE SEC 2024.</p> <h3 id="citation-bibtex-1">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{singh2024ovida,
  title={OVIDA: Orchestrator for Video Analytics on Disaggregated Architecture},
  author={Singh, Manavjeet and Rachuri, Sri Pramodh and Cao, Bryan Bo and Sharma, Abhinav and Bhumireddy, Venkata and Bronzino, Francesco and Das, Samir R. and Gandhi, Anshul and Jain, Shubham},
  journal={IEEE/ACM Symposium on Edge Computing},
  year={2024}
}
</code></pre></div></div> <h2 id="optimal-flow-admission-control-in-edge-computing-via-safe-reinforcement-learning">Optimal Flow Admission Control in Edge Computing via Safe Reinforcement Learning</h2> <p><em>Abstract.</em> With the uptake of intelligent data-driven applications, edge computing infrastructures necessitate a new generation of admission control algorithms to maximize system performance under limited and highly heterogeneous resources. In this paper, we study how to optimally select information flows which belong to different classes and dispatch them to multiple edge servers where applications perform flow analytic tasks. The optimal policy is obtained via the theory of constrained Markov decision processes (CMDP) to take into account the demand of each edge application for specific classes of flows, the constraints on computing capacity of edge servers and the constraints on access network capacity. We develop DRCPO, a specialized primal-dual Safe Reinforcement Learning (SRL) method which solves the resulting optimal admission control problem by reward decomposition. DRCPO operates optimal decentralized control and mitigates effectively state-space explosion while preserving optimality. Compared to existing Deep Reinforcement Learning (DRL) solutions, extensive results show that it achieves 15% higher reward on a wide variety of environments, while requiring on average only 50% learning episodes to converge. Finally, we further improve the system performance by matching DRCPO with load-balancing in order to dispatch optimally information flows to the available edge servers.</p> <h3 id="resources-2">Resources</h3> <p>The research paper was accepted to WiOpt 2024.</p> <p>You can access the source code of our RL models at this address: <a href="https://github.com/Andrea-Fox/DecomposedRCPO" rel="external nofollow noopener" target="_blank">https://github.com/Andrea-Fox/DecomposedRCPO</a></p> <h3 id="citation-bibtex-2">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{fox2024optimal,
  title={Optimal Flow Admission Control in Edge Computing via Safe Reinforcement Learning},
  author={Fox, Andrea and De Pellegrini, Francesco and Faticanti, Francescomaria and Altman, Eitan and Bronzino, Francesco},
  booktitle={International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks},
  year={2024}
}
</code></pre></div></div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>