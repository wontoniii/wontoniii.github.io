<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Cost-Aware ML on Networks | Francesco Bronzino</title> <meta name="author" content="Francesco Bronzino"> <meta name="description" content=""> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://fbronzino.com/projects/p_caml/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Francesco Bronzino</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research</a> </li> <li class="nav-item "> <a class="nav-link" href="/group/">Group</a> </li> <li class="nav-item "> <a class="nav-link" href="/positions/">Positions</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Cost-Aware ML on Networks</h1> <p class="post-description"></p> </header> <article> <p>Network management frequently utilizes machine learning to predict network performance and security based on traffic analysis. In such tasks, the representation of traffic data is as critical as the choice of the machine learning model. The features used by the model and their representations significantly impact the model’s accuracy and determine its feasibility and deployment practicality. Consequently, designing and evaluating these models necessitates considering not only their accuracy but also the system costs involved in deploying them within an operational network. Our work focuses on developing systems-driven approaches to design and train machine learning models that balance the trade-off between feature extraction costs and model accuracy.</p> <h2 id="jiti-dynamic-model-serving-for-just-in-time-traffic-inference">JITI: Dynamic Model Serving for Just-in-Time Traffic Inference</h2> <p><em>Abstract.</em> Accurate and efficient inference on network traffic through machine learning models is important for many management tasks, from traffic prioritization to anomaly detection. Existing ML inference pipelines differ primarily in their feature design: those based on summary flow statistics (e.g., packet sizes, inter-arrival times) are lightweight and efficient, though they may be less accurate for fine-grained classification, whereas pipelines that consume features directly from raw packet capture data can achieve higher accuracy but at significantly greater computational and resource cost. In this paper, we develop Just-in-Time Traffic Inference (JITI), a model serving system to support fast and accurate network traffic inference in raw packet-capture-based machine learning inference pipelines. Offline, JITI builds a curated pool of diverse trained models with varied feature and performance requirements. Online, JITI responds to traffic fluctuations via an adaptive scheduler that selects the model from the pool that offers the highest accuracy-to-efficiency ratio within system resource limits, thereby providing inference accuracy comparable to the more complex and resource-intensive packet-capture- based methods, with minimal efficiency compromise. Using traffic application inference as an example task, our evaluation shows that JITI improves inference performance by 18% over flow-statistics-based methods; when benchmarked against state-of-the-art packet-capture-based methods, JITI results in a worst-case drop in F1-Score of only 12.3%, while reducing the average inference decision time by∼127x.</p> <h3 id="resources">Resources</h3> <p>The research paper was accepted to ACM CoNEXT 2025.</p> <h3 id="citation-bibtex">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{jiang2025jiti,
  title={JITI: Dynamic Model Serving for Just-in-Time Traffic Inference},
  author={Jiang, Xi and Liu, Shinan and Naama, Saloua and Bronzino, Francesco and Schmitt, Paul and Feamster, Nick},
  journal={Proceedings of the ACM on Networking},
  volume={3},
  number={CoNEXT4},
  year={2025}
}
</code></pre></div></div> <h2 id="cato-end-to-end-optimization-of-ml-traffic-analysis-pipelines">CATO: End-to-end Optimization of ML Traffic Analysis Pipelines</h2> <p><em>Abstract.</em> Machine learning has shown tremendous potential for improving the capabilities of network traffic analysis applications, often outperforming simpler rule-based heuristics. However, ML-based solutions remain difficult to deploy in practice. Many existing approaches only optimize the predictive performance of their models, overlooking the practical challenges of running them against network traffic in real time. This is especially problematic in the domain of traffic analysis, where the efficiency of the serving pipeline is a critical factor in determining the usability of a model. In this work, we introduce CATO, a framework that addresses this problem by jointly optimizing the predictive performance and the associated systems costs of the serving pipeline. CATO leverages recent advances in multi-objective Bayesian optimization to efficiently identify Pareto-optimal configurations, and automatically compiles end-to-end optimized serving pipelines that can be deployed in real networks. Our evaluations show that compared to popular feature optimization techniques, CATO can provide up to 3600× lower inference latency and 3.7x higher zero-loss throughput while simultaneously achieving better model performance.</p> <h3 id="resources-1">Resources</h3> <p>The research paper was accepted to USENIX NSDI 2025.</p> <h3 id="citation-bibtex-1">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{wan2025cato,
  title={CATO: End-to-end Optimization of ML Traffic Analysis Pipelines},
  author={Wan, Gerry and Liu, Shinan and Bronzino, Francesco and Feamster, Nick and Durumeric, Zakir},
  journal={USENIX Symposium on Networked Systems Design and Implementation},
  year={2025}
}
</code></pre></div></div> <h2 id="traffic-refinery-cost-aware-network-traffic-analysis">Traffic Refinery: Cost-aware Network Traffic Analysis.</h2> <p>Relationships between systems costs and model performance would ideally inform machine learning pipelines during design; yet, most existing network traffic representation decisions are made <em>a priori</em>, without concern for future use by models. To enable this exploration, we have created <code class="language-plaintext highlighter-rouge">Traffic Refinery</code>, a system designed to offer <strong>flexibly extensible network data representations</strong>, the ability to assess the <strong>systems-related costs</strong> of these representations, and the <strong>effects of different representations on model performance</strong>.</p> <h3 id="system-overview">System Overview</h3> <p><img src="/assets/img/system.png" alt="Traffic Refinery System Overview Diagram" align="center" height="65%" width="65%"></p> <p>The figure shows an overview of the system architecture. <code class="language-plaintext highlighter-rouge">Traffic Refinery</code> is implemented in Go to exploit performance and flexibility, as well as its built-in benchmarking tools. The system has three components:</p> <ol> <li>A traffic categorization module responsible for associating network traffic with applications</li> <li>A packet capture and processing module that collects network flow statistics and tracks their state; moreover, this block implements a cache used to store flow state information</li> <li>An aggregation and storage module that queries the flow cache to obtain features and statistics about each traffic flow and stores higher-level features concerning the applications of interest for later processing</li> </ol> <h3 id="tldr-what-can-you-do-with-traffic-refinery">tl;dr: What Can You Do with Traffic Refinery?</h3> <ul> <li>Traffic (i.e., flows) are classified as “services” using either DNS domains or IP prefixes that the user can provide. <em>Note: DNS is increasingly encrypted, making this method less reliable. An area of ongoing research is privacy-preserving flow categorization.</em> </li> <li>For each service, users can select from a set of existing features or create additional ones to collect along with their frequency.</li> <li>The system-related costs of each feature can be profiled, enabling users to explore tradeoffs between ML model performance and feature costs in their particular environment.</li> </ul> <h3 id="why-is-traffic-refinery-necessary">Why is Traffic Refinery Necessary?</h3> <p>Network management increasingly relies on machine learning to make predictions about performance and security from network traffic. Often, the representation of the traffic is as important as the choice of the model. The features that the model relies on, and the representation of those features, ultimately determine model accuracy, as well as where and whether the model can be deployed in practice. Thus, the design and evaluation of these models ultimately requires understanding not only model accuracy but also the systems costs associated with deploying the model in an operational network.</p> <p>To highlight the need for <code class="language-plaintext highlighter-rouge">Traffic Refinery</code>, we show results from our <a href="https://dl.acm.org/doi/10.1145/3366704" rel="external nofollow noopener" target="_blank">prior work</a> by training multiple ML models to infer the resolution of encrypted video streaming applications over time using different data representations: 1) using only L3 features, as would be available using <code class="language-plaintext highlighter-rouge">netflow</code>; 2) adding transport layer features; and 3) adding application layer features to L3; and combining all features. The figure below shows the precision and recall achieved by each representation.</p> <p><img src="/assets/img/resolution_features.png" alt="Resolution inference features" align="center" height="40%" width="40%"></p> <p>As one might expect, a model trained solely with L3 features achieves the poorest performance. Hence, relying solely on features offered by existing network infrastructure would produce the worst performing models. On the other hand, combining Network and Application features results in more than a 10% increase in both precision and recall. This example showcases how limiting available data representations to the ones typically available from existing systems (e.g., NetFlow) can inhibit potential gains, highlighted by the blue-shaded area.</p> <p>Of course, any representation is possible if packet traces are the starting point, but raw packet capture can be prohibitive in operational networks, especially at high speeds. The figure below shows the amount of storage required to collect a one-hour packet capture from a live 10 Gbps link.</p> <p><img src="/assets/img/storage_profile.png" alt="Storage profile" align="center" height="40%" width="40%"></p> <p><code class="language-plaintext highlighter-rouge">Traffic Refinery</code> provides a new framework and system that enables a joint evaluation of both the conventional notions of machine learning performance (e.g., model accuracy) and the systems-level costs of different representations of network traffic.</p> <h3 id="resources-2">Resources</h3> <p>The research paper behind <code class="language-plaintext highlighter-rouge">Traffic Refinery</code> was accepted to ACM SIGMETRICS 2022, and published in ACM POMACS in December 2021.</p> <p>You can access the source code of the project as well as detailed documentation at <a href="https://traffic-refinery.github.io" rel="external nofollow noopener" target="_blank">https://traffic-refinery.github.io</a></p> <h3 id="citation-bibtex-2">Citation bibtex</h3> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{bronzino2021traffic,
  title={Traffic refinery: Cost-aware data representation for machine learning on network traffic},
  author={Bronzino, Francesco and Schmitt, Paul and Ayoubi, Sara and Kim, Hyojoon and Teixeira, Renata and Feamster, Nick},
  journal={Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  volume={5},
  number={3},
  pages={1--24},
  year={2021},
  publisher={ACM New York, NY, USA}
}
</code></pre></div></div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>